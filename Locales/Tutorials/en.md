## About the Model
- Place the model in the `models` folder.
- Only supports `.gguf` models.
- Remember to click "Load Model" after selecting one.

## About Parameters
- `max_tokens`: The maximum length of the generation (although it's set to 1024 by default, even 128 is enough).
- `n_gpu_layers`: The number of layers to use with GPU. -1 means using all GPUs; 0 means using CPU (since the model only has 200M, it's not much slower to use CPU anyway and can save some VRAM for SD).
- `temperature`: The temperature. The higher the value, the more random the generation results; the lower the value, the more conservative they are.
- `n_ctx`: The context length. The longer this value, the more information the model can remember, but it also increases VRAM usage.
- `top_p`: This parameter determines the range of vocabulary considered by the model. It samples from the probability distribution that has a cumulative probability of p or higher. For example, if top-p is set to 0.9, the model will select from the top 10% of vocabulary with the highest probabilities in the probability distribution. This method can increase the diversity of text generation.
- `min_p`: It sets a threshold that the model ignores any vocabulary with a probability below this threshold when generating text. For example, if min-p is set to 0.02, any vocabulary with a probability lower than 2% will not be considered for text generation. Setting it too high might reduce diversity in the output text.
- `top_k`: Top-k sampling is similar to top-p but uses a fixed number of vocabulary to sample from. Specifically, the model considers the highest k probabilities in the probability distribution and selects randomly from them. If top-k is set to 5, then at each step of generating text, the model will select from the top 5 most probable words in the probability distribution. This method can reduce the selection of low-probability vocabulary but might cause some words to be overused.
- `Seed`: No explanation needed (≧∀≦)ゞ Although setting it to `-1` or clicking "Random" will generate a random seed (if you use -1, you won't know what your previous seed was).

## About Tags
#### Expected Quality
- These are quality tags in the prompt, like `masterpiece`.

#### Mode
- Controls how the model generates content.
- `None`: Danbooru tags
- `tag_to_long`: Long natural language description
- `long_to_tag`: Long natural language description to Danbooru tags
- `short_to_long`: Short natural language description to long natural language description
- `short_to_tag`: Short natural language description to Danbooru tags
- `tag_to_short_to_long`: Danbooru tags to short natural language description and then to long natural language description
- `short_to_tag_to_long`: Short natural language description to Danbooru tags and then to long natural language description
- `short_to_long_to_tag`: Short natural language description to long natural language description and then to Danbooru tags

#### Target Length
- Controls the length of the generated content.

#### Tags
- All other tags you write when running the image.

## About Output
### Exclude Tags
- If a prompt includes any matching regular expression in these excluded tags, the corresponding tag will be considered as being met by the model's prompts and thus excluded.
- You need to fill in the exclude items with regular expressions.

### Results
- The text generated by the model.
- It is not the raw result but a processed version of the raw results; it cannot be used directly for generating images, but it provides more information than formatted results.
- If you want to see the raw results, uncomment the `#for testing` code and check them in the console.

### Formatted Results
- The text generated by the model after being processed into a format that can be used directly for generating images.